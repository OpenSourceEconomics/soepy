{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: Revisit state space components - order and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final product of this notebook we wish to obtain a simulated data set given prepsecified model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we supply all necessary inputs for the functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the model specification parameters and externally defined constants here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute entire file and make all variables/functions/classes\n",
    "# available for further use\n",
    "from ipynb.fs.full.model_spec import (num_periods,\n",
    "                                      num_choices,\n",
    "                                      educ_max,\n",
    "                                      educ_min,\n",
    "                                      mu,\n",
    "                                      delta,\n",
    "                                      optim_paras,\n",
    "                                      num_draws_emax,\n",
    "                                      num_agents_sim,\n",
    "                                      seed_emax,\n",
    "                                      seed_sim)\n",
    "\n",
    "# Import specified definitions only from given notebook\n",
    "import ipynb.fs\n",
    "from .defs.shared_constants import MISSING_INT, MISSING_FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary calculation of the education dimension (in final verion, created in attributes dictionary)\n",
    "educ_range = educ_max - educ_min + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final version of soepy, the function pyth_create_state_space is called before the backward_induction procedure. Here, we import the final output of the pyth_create_state_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the final output of pyth_create_state_space, args\n",
    "# In the modular implementation pyth_create_state_space will be called by by pyth_solve\n",
    "# pyth_solve is executed before pyth_simulate\n",
    "file_name = \"args_file.pkl\"\n",
    "# Open the file for reading\n",
    "file_object = open(file_name,'rb')  \n",
    "# load the object from the file into var args\n",
    "args = pickle.load(file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack objects from agrs\n",
    "states_all, states_number_period, mapping_states_index, max_states_period = args[0], args[1], args[2], args[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final version of soepy, also the function pyth_backward_induction is called before the simulation procedure. Here, we import the final output of the pyth_backward_induction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the final output of pyth_backward_induction, periods_emax\n",
    "# In the modular implementation pyth_create_state_space will be called by by pyth_solve\n",
    "# pyth_solve is executed before pyth_simulate\n",
    "file_name = \"periods_emax_file.pkl\"\n",
    "# Open the file for reading\n",
    "file_object = open(file_name,'rb')  \n",
    "# load the object from the file into var args\n",
    "periods_emax = pickle.load(file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to genrate draws of the error term distribution. There are two types of draws which come from the same distribution. \n",
    "\n",
    "First, we need draws which let us numerically integrate out the error term in a Monte Carlo simulation procedure. This is necessary for computing the continuation values and, ultimately, the value functions and the model's solution. Integating out the error term represents the process in which individuals in the model form expectations about the future. Assuming rational expectations and a known error term distribution up to its parameters, individuals take the possible realization of the error terms into account by computing the expected continuatio values over the distribution of the errors. For every period we simmulate num_draws_emax draws from the error term distribution. This has been done in the backward induction procedure.\n",
    "\n",
    "Second, we need another set of draws to represent our simulated reality. In our model, at the beginning of every new period, individuals are hit by a productivity shock. They are aware of the realization of the shock when making their labor supply choice for the period. For every period, we simmulate num_agents_sim draws of the error term distribution.\n",
    "\n",
    "To Do: Define take_draws and transform_disturbances as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create draws for simulated sample\n",
    "# Create draws from the standard normal distribution\n",
    "np.random.seed(seed_sim)\n",
    "draws_sim_standard = np.random.multivariate_normal(np.zeros(2), np.identity(2), (num_periods, num_agents_sim))\n",
    "\n",
    "# Transform disturbances to normal distribution with desired covariance matrix\n",
    "chocks_cov = [optim_paras[14]**2, optim_paras[15]**2] #Form covariances\n",
    "draws_sim_transformed = draws_sim_standard\n",
    "draws_sim_transformed[:,:,0] = draws_sim_standard[:,:,0]*chocks_cov[0]\n",
    "draws_sim_transformed[:,:,1] = draws_sim_standard[:,:,1]*chocks_cov[1]\n",
    "\n",
    "#Transform by taking the exponent\n",
    "draws_sim_transformed = np.exp(draws_sim_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to define additional function called in the loop to determine agents choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_utilities(educ_lev, exp_p, exp_f, optim_paras, draws):\n",
    "    \"\"\"Calculate flow utility for all choices by state and period.\"\"\"\n",
    "    \n",
    "    # Initialize container for utilities at state space point and period\n",
    "    utilities = np.tile(np.nan, num_choices)\n",
    "    \n",
    "    # Calculate utilities for the avaibale joices N, P, F\n",
    "    \n",
    "    # Non-employment\n",
    "    utilities[0] = 0\n",
    "    \n",
    "    #Part-time employment\n",
    "    utilities[1] = 18*(np.exp(np.dot(educ_lev, optim_paras[0:3])) + \n",
    "                       np.dot(educ_lev, optim_paras[3:6]) *\n",
    "                       (exp_p * np.dot(educ_lev, optim_paras[6:9]) + exp_f) \n",
    "                       * (1 - np.dot(educ_lev, optim_paras[9:12])) + 1\n",
    "                      + draws[0])**mu/mu + math.exp(optim_paras[12])\n",
    "    \n",
    "    # Full-time employment\n",
    "    utilities[2] = 38*(np.exp(np.dot(educ_lev, optim_paras[0:3])) + \n",
    "                       np.dot(educ_lev, optim_paras[3:6]) *\n",
    "                       (exp_p * np.dot(educ_lev, optim_paras[6:9]) + exp_f) \n",
    "                       * (1 - np.dot (educ_lev, optim_paras[9:12])) + 1\n",
    "                      + draws[1])**mu/mu + math.exp(optim_paras[13])\n",
    "    \n",
    "    return utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to simulate a sample of initial conditions. In this example, we need to assing a value for the years of education to every agent whose life-cycle we want to simulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ_years = list(range(educ_min, educ_max + 1))\n",
    "educ_years = np.random.choice(educ_years, num_agents_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simulate the model life-cycle experiences of the individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start count over all simulations/row (number of agents times number of periods)\n",
    "count = 0\n",
    "\n",
    "# Initialize container for the final output\n",
    "num_columns = 3 # count of the information units we wish to record\n",
    "dataset = np.tile(MISSING_FLOAT, (num_agents_sim*num_periods, num_columns))\n",
    "\n",
    "# Loop over all agents\n",
    "for i in range(num_agents_sim):\n",
    "    \n",
    "    # Extract education information:\n",
    "    educ_years_i = educ_years[i]\n",
    "    \n",
    "    if (educ_years_i <= 10):\n",
    "        educ_lev = [1,0,0]\n",
    "\n",
    "    elif (educ_years_i > 10) and (educ_years_i <= 12):\n",
    "        educ_lev = [0,1,0]\n",
    "\n",
    "    else:\n",
    "        educ_lev = [0,0,1]\n",
    "    \n",
    "    # Extract the indicator of the initial state for the individual\n",
    "    # depending on the individuals initial condition\n",
    "    educ_years_idx = educ_years_i - educ_min\n",
    "    initial_state_index = mapping_states_index[educ_years_idx, educ_years_idx, 0, 0, 0]\n",
    "    \n",
    "    # Assign the initial state as current state\n",
    "    current_state = states_all[educ_years_idx, initial_state_index, :].copy()\n",
    "    \n",
    "    # Loop over all remaining\n",
    "    for period in range(num_periods):\n",
    "        \n",
    "        # Extract state space components\n",
    "        choice_lagged, exp_p, exp_f = current_state[1], current_state[2], current_state[3]\n",
    "        \n",
    "        # Look up the indicator for the current state\n",
    "        k = mapping_states_index[period, educ_years_i - educ_min, choice_lagged - 1, exp_p, exp_f]\n",
    "        \n",
    "        # Record agent identifier and current period number in the dataset\n",
    "        dataset[count, :2] = i, period\n",
    "        \n",
    "        # Calculate choice specific value functions\n",
    "        # for individual, period and state space point\n",
    "        \n",
    "        # Extract the error term draws corresponding to\n",
    "        # period number and individual\n",
    "        corresponding_draws = draws_sim_transformed[period, i, :]\n",
    "        \n",
    "        # Calculate correspongind flow utilities\n",
    "        flow_utilities = calculate_utilities(educ_lev, exp_p, exp_f, optim_paras, corresponding_draws)\n",
    "        \n",
    "        # Obtain continuation values for all choices\n",
    "        # Initialize container for continuation values\n",
    "        continuation_values = np.tile(MISSING_FLOAT, 3)\n",
    "        \n",
    "        if period != (num_periods - 1):\n",
    "            \n",
    "            # Choice: Non-employment\n",
    "            # Create index for extracting the continuation value\n",
    "            future_idx = mapping_states_index[period + 1, educ_years_idx, 1 - 1, exp_f, exp_p]\n",
    "            # Extract continuation value\n",
    "            continuation_values[0] = periods_emax[period + 1, future_idx] \n",
    "\n",
    "            # Choice: Part-time\n",
    "            future_idx = mapping_states_index[period + 1, educ_years_idx, 2 - 1, exp_p + 1, exp_f]\n",
    "            continuation_values[1] = periods_emax[period + 1, future_idx]\n",
    "\n",
    "            # Choice: Full-time\n",
    "            future_idx = mapping_states_index[period + 1, educ_years_idx, 3 - 1, exp_p, exp_f + 1]\n",
    "            continuation_values[2] = periods_emax[period + 1, future_idx]\n",
    "        else:\n",
    "            continuation_value = np.tile(0.0, num_choices)\n",
    "        \n",
    "        # Calculate total values for all choices\n",
    "        value_functions = flow_utilities + delta*continuation_values\n",
    "        \n",
    "        # Determine choice as option with highest choice specific value function\n",
    "        max_idx = np.argmax(value_functions)\n",
    "        \n",
    "        \n",
    "        # Record output\n",
    "        # Record agent identifier, period number, choice, flow utility \n",
    "        dataset[count, :] = i, period, max_idx + 1\n",
    "        \n",
    "        \n",
    "        # Update state space component experience\n",
    "        current_state[max_idx + 1] += 1\n",
    "        \n",
    "        # Update state space component choice_lagged\n",
    "        current_state[1] = max_idx + 1\n",
    "        \n",
    "        # Update simulation/row count\n",
    "        count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
